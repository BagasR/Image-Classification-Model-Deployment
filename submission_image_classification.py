# -*- coding: utf-8 -*-
"""Submission_Image Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1attjH0KnmEIvupum4E7fe_Zmcds_rtdz

# **Classification**

Nama : Bagaskara
"""

!pip install -q kaggle

from google.colab import files
#Upload Kaggle API Key
files.upload()

!mkdir ~/.kaggle #make new directory in root folder
!cp kaggle.json ~/.kaggle/ #copy and paste kaggle API key to new directory
!chmod 600 ~/.kaggle/kaggle.json #permission
!kaggle datasets list

!kaggle datasets download -d muratkokludataset/rice-image-dataset

import zipfile,os

#Extract File
zipPath = '../content/rice-image-dataset.zip' #zip path in local
zipFile = zipfile.ZipFile(zipPath, 'r')
zipFile.extractall('../content/RiceImage') #extract to new directory
zipFile.close() #close connection to object

base_dir = '/content/RiceImage/Rice_Image_Dataset'

ar_dir = os.path.join(base_dir,'Arborio')
bas_dir = os.path.join(base_dir, 'Basmati')
ip_dir = os.path.join(base_dir, 'Ipsala')
ja_dir = os.path.join(base_dir, 'Jasmine')
ka_dir = os.path.join(base_dir, 'Karacadag')

Total_arborio = len(os.listdir(ar_dir))
Total_basmati = len(os.listdir(bas_dir))
Total_ipsala = len(os.listdir(ip_dir))
Total_jasmine = len(os.listdir(ja_dir))
Total_karacadag = len(os.listdir(ka_dir))

# Mencetak jumlah data
print("Total Data Arborio Image     : ",Total_arborio)
print("Total Data Basmati Image     : ",Total_basmati)
print("Total Data Ipsala Image      : ",Total_ipsala)
print("Total Data Jasmine Image     : ",Total_jasmine)
print("Total Data Karacadag Image   : ",Total_karacadag)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMG_HEIGHT = 150
IMG_WIDTH = 150
BATCH_SIZE = 70

#Ukuran validation 20% dari dataset
val_size = 0.2

#Pembuatan Train dan validation
train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range = 20,
    horizontal_flip = True,
    shear_range = 0.2,
    fill_mode = 'nearest',
    validation_split = val_size
)
val_datagen = ImageDataGenerator(
    rescale=1.0/255,
    validation_split = val_size
)
train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size = (IMG_HEIGHT, IMG_WIDTH),
    batch_size = BATCH_SIZE,
    class_mode = 'categorical',
    subset='training'
)

val_generator = val_datagen.flow_from_directory(
    base_dir,
    target_size = (IMG_HEIGHT, IMG_WIDTH),
    batch_size = BATCH_SIZE,
    class_mode = 'categorical',
    subset='validation'
)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout, BatchNormalization

model = Sequential([
    Conv2D(filters = 16, kernel_size = (5, 5), padding = 'Same', activation = 'relu', input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)),
    MaxPooling2D(pool_size = (2,2)),
    Dropout(0.2),
    BatchNormalization(),

    Conv2D(filters = 32, kernel_size = (3, 3), padding = 'Same', activation = 'relu'),
    MaxPooling2D(pool_size = (2,2), strides = (2, 2)),
    Dropout(0.2),

    Conv2D(filters = 64, kernel_size = (3, 3), padding = 'Same', activation = 'relu'),
    MaxPooling2D(pool_size = (2,2), strides = (2, 2)),
    Dropout(0.2),

    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(5, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

from tensorflow.keras.callbacks import Callback, EarlyStopping

#callback
class TargetCallback(Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') >= 0.95 and logs.get('val_accuracy') >= 0.95):
      print("\nAccuracy and Validation Accuracy has reached 95%!\nStop Train!")
      self.model.stop_training = True
Target = TargetCallback()

EarlyStop = EarlyStopping(
    monitor = 'val_loss',
    min_delta = 0.0001,
    patience = 5,
    verbose = 1,
    mode = 'auto'
)

History = model.fit(train_generator, epochs =  100, validation_data = val_generator, callbacks = [Target, EarlyStop], verbose = 1)

import matplotlib.pyplot as plt

print("Loss with Val_Loss Graph")
plt.plot(History.history['loss'])
plt.plot(History.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['train', 'test'], loc = 'upper right')
plt.show()

print("Acc with Val_Acc Graph")
plt.plot(History.history['accuracy'])
plt.plot(History.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='lower right')
plt.show()

import tensorflow as tf
import pathlib

#Save Model
export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('Model.tflite')
tflite_model_file.write_bytes(tflite_model)